{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试分类器分类性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#设置环境变量\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"chat\"\n",
    "\n",
    "from flask import Flask, request, Response, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "from utils.chat import navigate_chain, action_chain\n",
    "\n",
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import json\n",
    "import time\n",
    "MODEL = \"qwen2:7b-instruct-fp16\"\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\"\n",
    "KNOWLEDGE_DIR = \"knowledge\"\n",
    "OLLAMA_URL = \"http://10.214.149.209:14005\"\n",
    "\n",
    "df = pd.read_csv(\"测试用例.csv\", encoding=\"utf-8\")\n",
    "input_data = df[\"输入\"]\n",
    "record_result = df['分类器分类结果']\n",
    "record_time = df['分类器时间开销']\n",
    "df_web = pd.read_csv(\"csv/first_level.csv\", encoding=\"utf-8\")\n",
    "df_web_name = df_web[\"应用名称\"]\n",
    "df_web_url = df_web[\"link\"]\n",
    "website_dict = dict(zip(df_web_name,df_web_url))\n",
    "print(website_dict)\n",
    "\n",
    "# print(input_data)\n",
    "llm = ChatOllama(model=MODEL, format=\"json\", temperature=0,base_url=OLLAMA_URL)\n",
    "def route_action(qusetion:str):\n",
    "\n",
    "    route_prompt = PromptTemplate(\n",
    "            template=\"\"\"\n",
    "            You are an expert at selecting what to do next based on the user's input. \\n\n",
    "            You can choose to open a webpage or answer the user's question. \\n\n",
    "            Here are some websites you can open: {websites}\\n\n",
    "            Just return a JSON with the key 'action' and the value 'open' or 'answer'. \\n\n",
    "            Question: {question}\n",
    "            \"\"\",\n",
    "            input_variables=[\"question\"],\n",
    "        )\n",
    "    route_chain = route_prompt | llm | JsonOutputParser()\n",
    "    start_time = time.time()\n",
    "    route_result = route_chain.invoke({\"question\": qusetion,\"websites\":website_dict})\n",
    "    end_time = time.time()\n",
    "    print(\"qusetion:\",qusetion)\n",
    "    print(\"route_result:\",route_result)\n",
    "    print(\"route_time:\",end_time-start_time)\n",
    "    return {\"question\":qusetion,\"route_result\":route_result,\"route_time\":end_time-start_time}\n",
    "# warm up\n",
    "for i in input_data:\n",
    "    result = route_action(i)\n",
    "for i,question in enumerate(input_data):\n",
    "    result = route_action(question)\n",
    "    if \"action\" in result[\"route_result\"]:\n",
    "        if result[\"route_result\"]['action'] == 'open':\n",
    "            record_result[i] = '导航'\n",
    "        elif result[\"route_result\"]['action'] == 'answer':\n",
    "            record_result[i] = '问答'\n",
    "    record_time[i] = result[\"route_time\"]\n",
    "df['分类器分类结果'] = record_result\n",
    "df['分类器时间开销'] = record_time\n",
    "df.to_csv(\"测试用例.csv\", encoding=\"utf-8\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导航任务准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#设置环境变量\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"chat\"\n",
    "\n",
    "from flask import Flask, request, Response, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "from utils.chat import navigate_chain, action_chain\n",
    "\n",
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import json\n",
    "import time\n",
    "MODEL = \"qwen2:72b\"\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\"\n",
    "KNOWLEDGE_DIR = \"knowledge\"\n",
    "OLLAMA_URL = \"http://10.214.149.209:14005\"\n",
    "\n",
    "df = pd.read_csv(\"测试用例.csv\", encoding=\"utf-8\")\n",
    "input_data = df[\"输入\"]\n",
    "expect_result = df['类别']\n",
    "record_result = df['分类器分类结果']\n",
    "action_time = df['后续时间开销']\n",
    "output_data = df['输出']\n",
    "total_time = df['总时间开销']\n",
    "record_time = df['分类器时间开销']\n",
    "df_web = pd.read_csv(\"csv/first_level.csv\", encoding=\"utf-8\")\n",
    "df_web_name = df_web[\"应用名称\"]\n",
    "df_web_url = df_web[\"link\"]\n",
    "website_dict = dict(zip(df_web_name,df_web_url))\n",
    "# print(website_dict)\n",
    "SUBPAGES_DESCRIPTION = json.load(\n",
    "    open(os.path.join('csv','description','sync.json'),'r',encoding='utf-8')\n",
    ")\n",
    "WEBSITE_SUMMARY = json.load(\n",
    "    open(os.path.join('csv','description','summary.json'),'r',encoding='utf-8')\n",
    ")\n",
    "\n",
    "# print(input_data)\n",
    "llm = ChatOllama(model=MODEL, format=\"json\", temperature=0,base_url=OLLAMA_URL)\n",
    "def selece_best_three_website(grade:dict,threshold=5):\n",
    "    # 选择最好的三个website 要设置一个阈值\n",
    "    best_three_website = sorted(grade.items(),key=lambda x:x[1],reverse=True)[:3]\n",
    "    best_three_website = [x[0] for x in best_three_website if x[1] >= threshold]\n",
    "    return best_three_website\n",
    "def navigate_chain(question:str):\n",
    "    start_time = time.time()\n",
    "    grading_prompt =  PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevant of user's instructions to the website.\\n\n",
    "            Here is the user's instruction: {instruction}.\\n\n",
    "            Here is the website's name: {web_name}.\\n\n",
    "            Here is the website's summary: \\n{summary}.\\n\n",
    "            Please remember that the user is staff or student of Zhejiang University.\n",
    "            Please grade the relevance of the instruction to the website on a scale of 0 to 10.\\n\n",
    "            If the instruction is irrelevant to the website, please give a score of 0.\\n\n",
    "            If the instruction is highly relevant to the website, please give a score of 10.\\n\n",
    "            If the instruction is somewhat relevant to the website, please give a score between 0 and 10.\\n\n",
    "            Provide the score as a JSON with a single key 'score' and no premable or explanation.\"\"\",\n",
    "        input_variables=[\"instruction\",\"web_name\",\"summary\"],\n",
    "    )\n",
    "    grading_chain = grading_prompt | llm | JsonOutputParser()\n",
    "    second_grading_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing the relevance of user's instructions to the website according to the description of the websites' subpages.\\n\n",
    "            Here is the user's instruction: {instruction}.\\n\n",
    "            Here is the website's name: {web_name}.\\n\n",
    "            Here is the description of a subpage: \\n{subpages}.\\n\n",
    "            Please remember that the user is staff or student of Zhejiang University.\n",
    "            Please grade the relevance of the instruction to the website on a scale of 0 to 10.\\n\n",
    "            If the instruction is irrelevant to the website, please give a score of 0.\\n\n",
    "            If the instruction is highly relevant to the website, please give a score of 10.\\n\n",
    "            If the instruction is somewhat relevant to the website, please give a score between 0 and 10.\\n\n",
    "            Provide the score as a JSON with a single key 'score' and no premable or explanation.\"\"\",\n",
    "        input_variables=[\"instruction\",\"web_name\",\"subpages\"],\n",
    "    )\n",
    "    second_grading_chain = second_grading_prompt | llm | JsonOutputParser()\n",
    "    select_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a selector selecting the best subpage related to the user's instruction.\\n\n",
    "            Here is the user's instruction: {instruction}.\\n\n",
    "            Here is the subpages' url and description: \\n{subpages}.\\n\n",
    "            Please select the most relevant subpage to the user's instruction.\\n\n",
    "            Provide the selected subpage's url as a JSON with a single key 'url' and no premable or explanation.\"\"\",\n",
    "    )\n",
    "    select_chain = select_prompt | llm | JsonOutputParser()\n",
    "    grade = {}\n",
    "    # 第一轮打分\n",
    "    for web_name in WEBSITE_SUMMARY:\n",
    "        score = grading_chain.invoke({\n",
    "            \"instruction\":question,\n",
    "            \"web_name\":web_name,\n",
    "            \"summary\":WEBSITE_SUMMARY[web_name]\n",
    "        })\n",
    "        grade[web_name] = score['score']\n",
    "    best_three_website = selece_best_three_website(grade) #这里可能会是一个空列表，此时可以提前退出\n",
    "\n",
    "    # print(\"best_three_website:\",best_three_website)\n",
    "\n",
    "    # 第二轮打分，给子页面打分\n",
    "    grade = {} # 清空\n",
    "    description = {}\n",
    "\n",
    "    for web_name in best_three_website:\n",
    "        for subpages in SUBPAGES_DESCRIPTION[web_name]:\n",
    "            score = second_grading_chain.invoke({\n",
    "                \"instruction\":question,\n",
    "                \"web_name\":web_name,\n",
    "                \"subpages\":subpages\n",
    "            })\n",
    "            grade[subpages['url']] = score['score']\n",
    "            description[subpages['url']] = subpages['description']\n",
    "    best_three_subpages = selece_best_three_website(grade)\n",
    "    description = {url:description[url] for url in best_three_subpages}\n",
    "    print(description)\n",
    "    # TODO 两次都可能输出空列表，提前退出，统一做在这里\n",
    "    if len(best_three_subpages) == 0:\n",
    "        return {\"result\":\"无法找到相关页面\"}\n",
    "    # 选择最符合的子页面\n",
    "    select_subpage = select_chain.invoke({\n",
    "        \"instruction\": question,\n",
    "        \"subpages\":description\n",
    "    })\n",
    "    print(select_subpage['url'])\n",
    "    end_time = time.time()\n",
    "    return {\"question\":question,\"result\":select_subpage['url'],\"time\":end_time-start_time}\n",
    "# warm up\n",
    "for i in input_data:\n",
    "    result = navigate_chain(i)\n",
    "for i,question in enumerate(input_data):\n",
    "    if expect_result[i] == record_result[i] and expect_result[i] == '导航':\n",
    "        result = navigate_chain(question)\n",
    "        print(\"result:\",result)\n",
    "        action_time[i] = result[\"time\"]\n",
    "        total_time[i] = action_time[i] + record_time[i]\n",
    "        output_data = result[\"result\"]\n",
    "# df['分类器分类结果'] = record_result\n",
    "# df['分类器时间开销'] = record_time\n",
    "df[\"输出\"] = output_data\n",
    "df['后续时间开销'] = action_time\n",
    "df['总时间开销'] = total_time\n",
    "df.to_csv(\"测试用例.csv\", encoding=\"utf-8\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "df = pd.read_csv(\"测试用例.csv\", encoding=\"utf-8\")\n",
    "input = df[\"输入\"]\n",
    "output = df[\"输出\"]\n",
    "total_time = df[\"总时间开销\"]\n",
    "# warm up\n",
    "for i in range(3):\n",
    "    respoense = requests.post(\n",
    "        \"http://10.214.149.209:14008/chatgraph\",\n",
    "        json={\"message\":input[i]}\n",
    "        )\n",
    "for i,question in enumerate(input):\n",
    "    start_time = time.time()\n",
    "    response = requests.post(\n",
    "        \"http://10.214.149.209:14008/chatgraph\",\n",
    "        json={\"message\":question}\n",
    "        )\n",
    "    end_time = time.time()\n",
    "    result = response.json()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#设置环境变量\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"chat\"\n",
    "\n",
    "from flask import Flask, request, Response, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "from utils.chat import navigate_chain, action_chain\n",
    "\n",
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "#TODO 现在可以先不接入，先在main.py中测试，\n",
    "#TODO 需要考虑在前端的调用形式 目前预估只能连贯执行完成，不能中断 （考虑使用扩展插件的形式）\n",
    "MODEL = \"qwen2:7b-instruct-fp16\"\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\"\n",
    "KNOWLEDGE_DIR = \"knowledge\"\n",
    "OLLAMA_URL = \"http://10.214.149.209:14005\"\n",
    "\n",
    "SUBPAGES_DESCRIPTION = json.load(\n",
    "    open(os.path.join('csv','description','sync.json'),'r',encoding='utf-8')\n",
    ")\n",
    "WEBSITE_SUMMARY = json.load(\n",
    "    open(os.path.join('csv','description','summary.json'),'r',encoding='utf-8')\n",
    ")\n",
    "\n",
    "df_web = pd.read_csv(\"csv/first_level.csv\", encoding=\"utf-8\")\n",
    "df_web_name = df_web[\"应用名称\"]\n",
    "df_web_url = df_web[\"link\"]\n",
    "website_dict = dict(zip(df_web_name,df_web_url))\n",
    "\n",
    "#从pdf加载knowledge\n",
    "filelist = os.listdir(KNOWLEDGE_DIR)\n",
    "merge_pages = []\n",
    "for file in filelist:\n",
    "    if file.endswith('.pdf'):\n",
    "        file_path = os.path.join(KNOWLEDGE_DIR, file)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        pages = loader.load_and_split()\n",
    "        merge_pages += pages\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=400, add_start_index=True\n",
    ")\n",
    "all_splitter = text_splitter.split_documents(merge_pages)\n",
    "vectorstore = Chroma.from_documents(all_splitter,embedding=OllamaEmbeddings(model=EMBEDDING_MODEL,base_url=OLLAMA_URL))\n",
    "\n",
    "def selece_best_three_website(grade:dict,threshold=5):\n",
    "    # 选择最好的三个website 要设置一个阈值\n",
    "    best_three_website = sorted(grade.items(),key=lambda x:x[1],reverse=True)[:3]\n",
    "    best_three_website = [x[0] for x in best_three_website if x[1] >= threshold]\n",
    "    return best_three_website\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[Document]\n",
    "    action: str\n",
    "\n",
    "#NODE\n",
    "def open_navigation(state: GraphState):\n",
    "    \"\"\"\n",
    "    Open the webpage based on the question.\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        state with url in generation\n",
    "    \"\"\"\n",
    "    print(\"---OPEN NAVIGATION---\")\n",
    "    question = state[\"question\"]\n",
    "    # LLM\n",
    "    llm = ChatOllama(model=MODEL, format=\"json\", temperature=0, base_url=OLLAMA_URL)\n",
    "    grading_prompt =  PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevant of user's instructions to the website.\\n\n",
    "            Here is the user's instruction: {instruction}.\\n\n",
    "            Here is the website's name: {web_name}.\\n\n",
    "            Here is the website's summary: \\n{summary}.\\n\n",
    "            Please remember that the user is staff or student of Zhejiang University.\n",
    "            Please grade the relevance of the instruction to the website on a scale of 0 to 10.\\n\n",
    "            If the instruction is irrelevant to the website, please give a score of 0.\\n\n",
    "            If the instruction is highly relevant to the website, please give a score of 10.\\n\n",
    "            If the instruction is somewhat relevant to the website, please give a score between 0 and 10.\\n\n",
    "            Provide the score as a JSON with a single key 'score' and no premable or explanation.\"\"\",\n",
    "        input_variables=[\"instruction\",\"web_name\",\"summary\"],\n",
    "    )\n",
    "    grading_chain = grading_prompt | llm | JsonOutputParser()\n",
    "    second_grading_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing the relevance of user's instructions to the website according to the description of the websites' subpages.\\n\n",
    "            Here is the user's instruction: {instruction}.\\n\n",
    "            Here is the website's name: {web_name}.\\n\n",
    "            Here is the description of a subpage: \\n{subpages}.\\n\n",
    "            Please remember that the user is staff or student of Zhejiang University.\n",
    "            Please grade the relevance of the instruction to the website on a scale of 0 to 10.\\n\n",
    "            If the instruction is irrelevant to the website, please give a score of 0.\\n\n",
    "            If the instruction is highly relevant to the website, please give a score of 10.\\n\n",
    "            If the instruction is somewhat relevant to the website, please give a score between 0 and 10.\\n\n",
    "            Provide the score as a JSON with a single key 'score' and no premable or explanation.\"\"\",\n",
    "        input_variables=[\"instruction\",\"web_name\",\"subpages\"],\n",
    "    )\n",
    "    second_grading_chain = second_grading_prompt | llm | JsonOutputParser()\n",
    "    select_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a selector selecting the best subpage related to the user's instruction.\\n\n",
    "            Here is the user's instruction: {instruction}.\\n\n",
    "            Here is the subpages' url and description: \\n{subpages}.\\n\n",
    "            Please select the most relevant subpage to the user's instruction.\\n\n",
    "            Provide the selected subpage's url as a JSON with a single key 'url' and no premable or explanation.\"\"\",\n",
    "    )\n",
    "    select_chain = select_prompt | llm | JsonOutputParser()\n",
    "    grade = {}\n",
    "    # 第一轮打分\n",
    "    for web_name in WEBSITE_SUMMARY:\n",
    "        score = grading_chain.invoke({\n",
    "            \"instruction\":question,\n",
    "            \"web_name\":web_name,\n",
    "            \"summary\":WEBSITE_SUMMARY[web_name]\n",
    "        })\n",
    "        grade[web_name] = score['score']\n",
    "    best_trhee_website = selece_best_three_website(grade) #这里可能会是一个空列表，此时可以提前退出\n",
    "\n",
    "    print(\"best_trhee_website:\",best_trhee_website)\n",
    "\n",
    "    # 第二轮打分，给子页面打分\n",
    "    grade = {} # 清空\n",
    "    description = {}\n",
    "\n",
    "    for web_name in best_trhee_website:\n",
    "        for subpages in SUBPAGES_DESCRIPTION[web_name]:\n",
    "            score = second_grading_chain.invoke({\n",
    "                \"instruction\":question,\n",
    "                \"web_name\":web_name,\n",
    "                \"subpages\":subpages\n",
    "            })\n",
    "            grade[subpages['url']] = score['score']\n",
    "            description[subpages['url']] = subpages['description']\n",
    "    best_three_subpages = selece_best_three_website(grade)\n",
    "    description = {url:description[url] for url in best_three_subpages}\n",
    "    print(description)\n",
    "    # TODO 两次都可能输出空列表，提前退出，统一做在这里\n",
    "    if len(best_three_subpages) == 0:\n",
    "        return {\n",
    "            \"question\": question, \n",
    "            \"generation\": {'action':'answer','content':'万分抱歉，我当前的能力无法帮助您解决该问题。'}, \n",
    "            \"documents\": state[\"documents\"], \n",
    "            \"action\": \"answer\"\n",
    "        }\n",
    "    # 选择最符合的子页面\n",
    "    select_subpage = select_chain.invoke({\n",
    "        \"instruction\": question,\n",
    "        \"subpages\":description\n",
    "    })\n",
    "    print(select_subpage['url'])\n",
    "    return {\n",
    "        \"question\": question, \n",
    "        \"generation\": {'action':'open','content':select_subpage['url']}, \n",
    "        \"documents\": state[\"documents\"], \n",
    "        \"action\": \"open\"\n",
    "    }\n",
    "    # navigation_prompt = PromptTemplate(\n",
    "    #     template=\"\"\"You are an expert at selecting related content for a user's question based on the document list {list}. \\n\n",
    "    #     Do not be stringent with the keywords in the question; focus on related topics. \\n\n",
    "    #     Provide up to three options related to the user's question from the document list {list}.\\n\n",
    "    #     Return a JSON with the key 'url' and no preamble or explanation. \\n\n",
    "    #     If there are no related documents, return a JSON with the key 'option' and the value 'none'. \\n\n",
    "    #     Question: {question}\"\"\",\n",
    "    #     input_variables=[\"question\",\"list\"],\n",
    "    # )\n",
    "    # d_list = []\n",
    "    # d_dict = {}\n",
    "    # with open('apps.json','r') as json_file:\n",
    "    #     loaded_data = json.load(json_file)\n",
    "    #     for value in loaded_data.values():\n",
    "    #         d_list.append(value['app'])\n",
    "    #         d_dict[value['app']] = value['link']\n",
    "    # navigation_chain = navigation_prompt | llm | JsonOutputParser()\n",
    "    # navigation_result = navigation_chain.invoke({\"question\": question, \"list\": d_list})\n",
    "    # try:\n",
    "    #     url = d_dict.get(navigation_result['url'])\n",
    "    # except:\n",
    "    #     raise ValueError(\"The url is not found\")\n",
    "    # generation = {'action':'open','content':url}\n",
    "    # print(\"generation:\", generation)\n",
    "    # return {\"question\": question, \"generation\": generation, \"documents\": state[\"documents\"], \"action\": \"open\"}\n",
    "\n",
    "def retieve_docs(state: GraphState):\n",
    "    \"\"\"\n",
    "    Retrieve documents based on the question.\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print('---RETRIEVE DOCS---')\n",
    "    question = state[\"question\"]\n",
    "    retiever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={'k': 5, 'fetch_k': 50}\n",
    "    ) #retiever定义在内部，根据情况可以更改参数\n",
    "    documents = retiever.get_relevant_documents(question)\n",
    "    print(\"documents:\", documents)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def grade_documents(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "    print(\"---GRADE DOCS---\")\n",
    "    question = state[\"question\"]\n",
    "    llm = ChatOllama(model=MODEL, format=\"json\", temperature=0, base_url=OLLAMA_URL)\n",
    "    documents = state[\"documents\"]\n",
    "    retrieval_grade_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keywords related to the user question, grade it as relevant. \\n\n",
    "        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "        Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\"\"\",\n",
    "        input_variables=[\"document\", \"question\"],\n",
    "    )\n",
    "    retrieval_grade_chain = retrieval_grade_prompt | llm | JsonOutputParser()\n",
    "    filtered_documents = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grade_chain.invoke({\"document\": d.page_content, \"question\": question})\n",
    "        try:\n",
    "            grade = score[\"score\"]\n",
    "        except:\n",
    "            raise ValueError(\"The score is not found\")\n",
    "        if grade == \"yes\":\n",
    "            filtered_documents.append(d)\n",
    "    print(\"filtered_documents:\", filtered_documents)\n",
    "    return {\"documents\": filtered_documents, \"question\": question}\n",
    "\n",
    "def generate_answer(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE ANSWER---\")\n",
    "    question = state[\"question\"]\n",
    "    context = \"\"\n",
    "    for doc in state[\"documents\"]:\n",
    "        context += doc.page_content + \"\\n\\n\"\n",
    "    llm = ChatOllama(model=MODEL, temperature=0,base_url=OLLAMA_URL)\n",
    "    answer_prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "            You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. Answer using the same language as in the question. Some sentences in the context are redundant. If you don't know the answer, just say that you don't know. Keep the answer concise.\\n\n",
    "            Question: {question} \\n\n",
    "            Context: {context} \\n\n",
    "        \"\"\",\n",
    "        input_variables=[\"question\", \"context\"],\n",
    "    )\n",
    "    answer_chain = answer_prompt | llm | StrOutputParser()\n",
    "    generation = answer_chain.invoke({\"question\": question, \"context\": context})\n",
    "    print(\"generation:\", generation)\n",
    "    new_generation = {\"action\":\"answer\",\"content\":generation}\n",
    "    return {\"question\": question, \"generation\": new_generation, \"documents\": state[\"documents\"], \"action\": \"answer\"}\n",
    "    \n",
    "\n",
    "# EDGE\n",
    "def route_action(state: GraphState):\n",
    "    \"\"\"\n",
    "    Decide the next action based on the current state.\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    print(\"---ROUTE ACTION---\")\n",
    "    qusetion = state[\"question\"]\n",
    "    print(\"question:\", qusetion)\n",
    "    #创建route_chain\n",
    "    llm = ChatOllama(model=MODEL, format=\"json\", temperature=0,base_url=OLLAMA_URL)\n",
    "    route_prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are an expert at selecting what to do next based on the user's input. \\n\n",
    "        You can choose to open a webpage or answer the user's question. \\n\n",
    "        Here are some websites you can open: {websites}\\n\n",
    "        Just return a JSON with the key 'action' and the value 'open' or 'answer'. \\n\n",
    "        Question: {question}\n",
    "        \"\"\",\n",
    "        input_variables=[\"question\",\"websites\"],\n",
    "    )\n",
    "    route_chain = route_prompt | llm | JsonOutputParser()\n",
    "    route_result = route_chain.invoke({\"question\": qusetion,\"websites\":website_dict})\n",
    "    #返回一个json，包含action，值为open或answer\n",
    "    print(\"route_result:\", route_result)\n",
    "    if \"action\" in route_result:\n",
    "        if route_result[\"action\"] == \"open\":\n",
    "            return \"open\"\n",
    "        elif route_result[\"action\"] == \"answer\":\n",
    "            return \"answer\"\n",
    "    raise ValueError(\"The action is not found\")\n",
    "\n",
    "chat_workflow = StateGraph(GraphState)\n",
    "#define nodes\n",
    "chat_workflow.add_node(\"open\", open_navigation)\n",
    "chat_workflow.add_node(\"retrieve\", retieve_docs)\n",
    "chat_workflow.add_node(\"grade\", grade_documents)\n",
    "chat_workflow.add_node(\"answer\", generate_answer)\n",
    "\n",
    "#build graph\n",
    "chat_workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_action,\n",
    "    {\n",
    "        \"open\": \"open\",\n",
    "        \"answer\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "chat_workflow.add_edge(\"open\", END)\n",
    "chat_workflow.add_edge(\"retrieve\", \"grade\")\n",
    "chat_workflow.add_edge(\"grade\", \"answer\")\n",
    "chat_workflow.add_edge(\"answer\", END)\n",
    "\n",
    "chat_app = chat_workflow.compile()\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "df = pd.read_csv(\"测试用例.csv\", encoding=\"utf-8\")\n",
    "input = df[\"输入\"]\n",
    "output = df[\"输出\"]\n",
    "total_time = df[\"总时间开销\"]\n",
    "rag_doc = df['rag']\n",
    "# warm up\n",
    "for i in range(3):\n",
    "    llm_result = chat_app.invoke({\"question\": input[i]})\n",
    "    print(f\"warm up {i}\")\n",
    "for i,question in enumerate(input):\n",
    "    start_time = time.time()\n",
    "    llm_result = chat_app.invoke({\"question\": question})\n",
    "    end_time = time.time()\n",
    "    print(llm_result)\n",
    "    total_time[i] = end_time - start_time\n",
    "    if 'documents' in llm_result:\n",
    "        rag_doc[i] = str(llm_result['documents'])\n",
    "    output[i] = llm_result['generation']['content']\n",
    "\n",
    "df[\"输出\"] = output\n",
    "df[\"rag\"] = rag_doc\n",
    "df[\"总时间开销\"] = total_time\n",
    "df.to_csv(\"测试用例.csv\", encoding=\"utf-8\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatzju",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
